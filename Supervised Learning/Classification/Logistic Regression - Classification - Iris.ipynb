{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of X: (100, 4)\n",
      "Dimension of y: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "X independent variables: \n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]]\n",
      "y dependent variable: \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "data_set = load_iris()\n",
    "X_independent_variables = data_set.data[0:100, :]\n",
    "y_dependent_variable = data_set.target[0:100]\n",
    "\n",
    "print(f\"Dimension of X: {X_independent_variables.shape}\")\n",
    "print(f\"Dimension of y: {y_dependent_variable}\")\n",
    "print(f\"X independent variables: \\n{X_independent_variables}\")\n",
    "print(f\"y dependent variable: \\n{y_dependent_variable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Standardizing data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize_data(X):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    sigma = np.std(X, axis=0)\n",
    "    X_standarded = (X-mean)/sigma\n",
    "    return X_standarded, mean, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, percentage_train = 80.0):\n",
    "    np.random.seed(100)\n",
    "    number_of_all_datapoints = X.shape[0]\n",
    "    number_of_train_datapoints = int(np.round(X.shape[0]*percentage_train/100))\n",
    "    indices_train = np.random.choice(number_of_all_datapoints, number_of_train_datapoints, replace=False).tolist()\n",
    "    indices_test = list(set(np.arange(X.shape[0]))-set(indices_train))\n",
    "    \n",
    "    X_train = X[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    X_test = X[indices_test, :]\n",
    "    y_test = y[indices_test]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of X training data: (80, 4)\n",
      "Dimension of y training data: (80,)\n",
      "X training data: [[4.9 3.6 1.4 0.1]\n",
      " [6.  2.2 4.  1. ]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "y training data: [0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1\n",
      " 1 1 0 0 0 0]\n",
      "X test data: [[4.7 3.2 1.3 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.1 2.5 3.  1.1]]\n",
      "y test data: [0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = split_data(X_independent_variables, y_dependent_variable)\n",
    "\n",
    "print(f\"Dimension of X training data: {X_train.shape}\")\n",
    "print(f\"Dimension of y training data: {y_train.shape}\")\n",
    "\n",
    "print(f\"X training data: {X_train}\")\n",
    "print(f\"y training data: {y_train}\")\n",
    "print(f\"X test data: {X_test}\")\n",
    "print(f\"y test data: {y_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standarded X training data: [[-0.89579773  1.15786408 -1.04172561 -1.25212374]\n",
      " [ 0.81418492 -2.05205614  0.74164004  0.32673632]\n",
      " [-0.74034476  0.69930405 -0.90454364 -0.72583705]\n",
      " [-1.5176096  -1.82277613 -1.1103166  -0.90126595]\n",
      " [-0.74034476  0.24074402 -1.17890759 -1.07669484]\n",
      " [-0.74034476 -0.21781602 -0.90454364 -1.07669484]\n",
      " [ 0.03692008  0.92858407 -1.1103166  -1.07669484]\n",
      " [ 0.03692008  2.53354418 -1.04172561 -1.07669484]\n",
      " [ 1.90235569 -0.21781602  1.42754991  1.55473858]\n",
      " [-0.58489179  1.3871441  -0.97313463 -0.72583705]\n",
      " [ 0.81418492  0.69930405  1.08459498  1.37930968]\n",
      " [ 2.36871459  0.24074402  1.22177695  1.02845189]\n",
      " [ 0.50327898 -1.13493608  0.74164004  0.67759411]\n",
      " [ 0.19237305 -1.3642161   0.67304906  0.50216521]\n",
      " [ 0.34782602 -0.44709603  0.87882202  0.853023  ]\n",
      " [ 0.81418492 -0.44709603  1.08459498  1.20388079]\n",
      " [ 1.28054382 -1.3642161   1.35895893  1.20388079]\n",
      " [-0.11853289  1.84570413 -0.83595265 -0.72583705]\n",
      " [-0.74034476  0.92858407 -1.1103166  -0.90126595]\n",
      " [-1.05125069  0.69930405 -0.90454364 -1.07669484]\n",
      " [-1.20670366  0.24074402 -0.90454364 -1.07669484]\n",
      " [ 0.81418492 -0.90565606  1.4961409   1.37930968]\n",
      " [ 0.50327898 -0.90565606  0.67304906  0.67759411]\n",
      " [-0.74034476  0.92858407 -0.90454364 -0.37497926]\n",
      " [-0.42943882  0.69930405 -1.04172561 -1.07669484]\n",
      " [-1.36215663  1.15786408 -1.31608956 -1.07669484]\n",
      " [-0.58489179  0.47002403 -0.83595265 -0.55040816]\n",
      " [ 0.03692008 -1.13493608  1.01600399  0.67759411]\n",
      " [ 1.90235569  0.011464    1.22177695  1.20388079]\n",
      " [-0.11853289  0.69930405 -0.83595265 -1.07669484]\n",
      " [-0.42943882  2.30426416 -0.97313463 -1.25212374]\n",
      " [-1.36215663  0.69930405 -1.04172561 -0.90126595]\n",
      " [-1.36215663  0.011464   -0.97313463 -1.07669484]\n",
      " [-1.05125069 -0.21781602 -1.04172561 -1.25212374]\n",
      " [ 1.43599679  0.24074402  1.08459498  1.20388079]\n",
      " [-0.11853289 -0.21781602  1.08459498  1.20388079]\n",
      " [ 0.96963789 -0.67637605  1.22177695  0.67759411]\n",
      " [ 0.19237305 -0.44709603  0.4672761   0.853023  ]\n",
      " [ 1.59144976 -0.67637605  1.15318597  1.20388079]\n",
      " [ 1.12509085 -2.05205614  1.08459498  1.20388079]\n",
      " [ 1.74690272 -0.21781602  1.01600399  1.02845189]\n",
      " [ 1.43599679 -0.44709603  0.94741301  0.853023  ]\n",
      " [-0.89579773 -1.59349611  0.26150314  0.32673632]\n",
      " [-1.67306256  0.24074402 -1.1103166  -1.07669484]\n",
      " [ 2.05780866 -0.67637605  1.29036794  1.02845189]\n",
      " [ 0.34782602 -0.67637605  0.81023103  0.853023  ]\n",
      " [-0.58489179  0.92858407 -1.04172561 -0.90126595]\n",
      " [-0.74034476 -1.82277613  0.26150314  0.32673632]\n",
      " [ 0.96963789 -0.44709603  1.22177695  1.02845189]\n",
      " [-0.58489179  0.92858407 -1.04172561 -1.07669484]\n",
      " [ 0.34782602  1.61642411 -0.83595265 -0.90126595]\n",
      " [-0.58489179  1.61642411 -0.69877068 -0.72583705]\n",
      " [-1.67306256 -0.21781602 -1.1103166  -1.07669484]\n",
      " [-1.05125069 -0.21781602 -1.04172561 -0.90126595]\n",
      " [-0.58489179  0.69930405 -0.97313463 -1.07669484]\n",
      " [ 0.65873195  0.24074402  1.29036794  1.73016747]\n",
      " [ 0.19237305 -0.90565606  0.87882202  0.853023  ]\n",
      " [-1.05125069  0.011464   -0.90454364 -1.07669484]\n",
      " [ 0.96963789 -0.67637605  0.74164004  0.853023  ]\n",
      " [-0.58489179  1.61642411 -0.90454364 -1.07669484]\n",
      " [ 1.28054382  0.47002403  1.22177695  1.37930968]\n",
      " [ 0.03692008 -1.59349611  0.60445807  0.50216521]\n",
      " [ 0.96963789 -0.21781602  1.15318597  1.02845189]\n",
      " [ 0.19237305 -0.21781602  0.81023103  0.853023  ]\n",
      " [-0.58489179  1.61642411 -0.97313463 -0.90126595]\n",
      " [ 0.03692008 -1.59349611  0.53586708  0.32673632]\n",
      " [ 0.34782602 -0.67637605  1.08459498  0.853023  ]\n",
      " [ 0.03692008 -1.3642161   0.74164004  0.853023  ]\n",
      " [ 0.65873195 -0.21781602  0.87882202  1.20388079]\n",
      " [ 1.90235569  0.011464    1.01600399  1.02845189]\n",
      " [-1.36215663  0.24074402 -1.04172561 -1.07669484]\n",
      " [-0.74034476  0.47002403 -1.04172561 -1.07669484]\n",
      " [-0.74034476  0.69930405 -0.97313463 -1.07669484]\n",
      " [ 1.12509085 -0.44709603  0.94741301  0.853023  ]\n",
      " [-0.42943882 -0.90565606  0.67304906  1.02845189]\n",
      " [ 0.34782602 -0.21781602  0.87882202  0.67759411]\n",
      " [-1.82851553 -0.21781602 -1.24749857 -1.25212374]\n",
      " [-0.89579773 -0.21781602 -1.04172561 -1.07669484]\n",
      " [-0.11853289  0.69930405 -0.97313463 -0.72583705]\n",
      " [-0.74034476  1.15786408 -1.04172561 -1.07669484]]\n",
      "Standarded X testing data: [[-1.21267813  0.13912477 -0.98260066 -0.92120197]\n",
      " [-1.69774938 -0.35190384 -0.90872092 -0.92120197]\n",
      " [-0.88929729 -0.02455143 -0.83484117 -1.11513923]\n",
      " [-0.08084521  0.9575058  -0.83484117 -0.92120197]\n",
      " [ 0.56591646  1.44853442 -1.05648041 -0.92120197]\n",
      " [ 0.40422604  2.10323924 -0.83484117 -0.53332746]\n",
      " [-0.08084521  1.28485821 -0.98260066 -0.53332746]\n",
      " [-1.05098771  0.46647719 -0.53932217 -0.92120197]\n",
      " [-0.40422604  0.63015339 -0.83484117 -0.92120197]\n",
      " [-0.88929729 -0.02455143 -0.83484117 -0.92120197]\n",
      " [-0.24253563  0.9575058  -0.83484117 -0.92120197]\n",
      " [ 2.34451104 -0.02455143  1.67707031  1.59998237]\n",
      " [ 0.08084521 -1.33396107  1.01215256  1.21210786]\n",
      " [ 1.85943979 -0.35190384  1.45543106  1.21210786]\n",
      " [-0.72760688 -1.82498969  0.64275382  0.63029608]\n",
      " [ 0.24253563 -0.18822764  1.38155131  1.59998237]\n",
      " [ 0.56591646 -0.67925625  1.08603231  0.63029608]\n",
      " [ 0.40422604 -0.84293246  0.64275382  0.63029608]\n",
      " [ 1.37436854 -1.33396107  1.30767156  1.21210786]\n",
      " [-0.56591646 -1.00660866  0.27335507  0.82423334]]\n"
     ]
    }
   ],
   "source": [
    "X_train_standarded, _, _ = standarize_data(X_train)\n",
    "X_test_standarded, mean_test, sigma_test = standarize_data(X_test)\n",
    "\n",
    "print(f\"Standarded X training data: {X_train_standarded}\")\n",
    "print(f\"Standarded X testing data: {X_test_standarded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logistic Regression for classification</h1>\n",
    "<h3 style=\"color: green\">Hypothesis:</h3>\n",
    "\n",
    "\\begin{equation*}\n",
    "    h_\\theta(x) = g(\\theta^Tx)\n",
    "\\end{equation*}\n",
    "\n",
    "Hypothesis is a function, that maps our inputs and model's parameters to the output results. <b>It's our model!</b>\n",
    "\n",
    "<h4>Sigmoid:</h4>\n",
    "\n",
    "\\begin{equation*}\n",
    "    g(z) = \\frac{1}{1+e^{-z}}\n",
    "\\end{equation*}\n",
    "\n",
    "<img src='https://miro.medium.com/v2/resize:fit:1280/1*OUOB_YF41M-O4GgZH_F2rw.png' />\n",
    "\n",
    "<h3 style=\"color: red\">Cost function: </h3>\n",
    "\n",
    "\\begin{equation*}\n",
    "\tJ(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} [-y^{(i)}\\log(h_\\theta(x^{(i)})) - (1-y^{(i)})\\log(1-h_\\theta(x^{(i)}))]\t\n",
    "\\end{equation*}\n",
    "\n",
    "It's Binary Cross Entropy that will produce cost of our model!.\n",
    "We must <b>minimize cost function</b> by changing the model's parameters (theta).\n",
    "\n",
    "<h3 style=\"color: cyan\">Optimization by using <b>Linear Gradient</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "    \\theta_n := \\theta_n - \\alpha \\cdot \\frac{\\partial J(\\theta)}{\\partial \\theta_n}\n",
    "\\end{equation*}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
