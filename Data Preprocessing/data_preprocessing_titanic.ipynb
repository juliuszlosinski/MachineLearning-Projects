{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing - Titanic data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importing libraries (Pandas, NumPy, Label Encoder, OneHot Encoder and ColumnTransformer from Sci-kit learn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Loading data by using Pandas and displaing missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      "\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "missing_values = dataset.isna().sum()\n",
    "\n",
    "print(f\"\\nMissing values:\\n\\n{missing_values}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Splitting data to X independent variables/ Matrix of Features and y dependent variable/ Vector (output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X independent variables/ Matrix of features: \n",
      "\n",
      "     PassengerId  Pclass                                               Name   \n",
      "0              2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  \\\n",
      "1              4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
      "2              7       1                            McCarthy, Mr. Timothy J   \n",
      "3             11       3                    Sandstrom, Miss. Marguerite Rut   \n",
      "4             12       1                           Bonnell, Miss. Elizabeth   \n",
      "..           ...     ...                                                ...   \n",
      "178          872       1   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)   \n",
      "179          873       1                           Carlsson, Mr. Frans Olof   \n",
      "180          880       1      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)   \n",
      "181          888       1                       Graham, Miss. Margaret Edith   \n",
      "182          890       1                              Behr, Mr. Karl Howell   \n",
      "\n",
      "        Sex   Age  SibSp  Parch    Ticket     Fare        Cabin Embarked  \n",
      "0    female  38.0      1      0  PC 17599  71.2833          C85        C  \n",
      "1    female  35.0      1      0    113803  53.1000         C123        S  \n",
      "2      male  54.0      0      0     17463  51.8625          E46        S  \n",
      "3    female   4.0      1      1   PP 9549  16.7000           G6        S  \n",
      "4    female  58.0      0      0    113783  26.5500         C103        S  \n",
      "..      ...   ...    ...    ...       ...      ...          ...      ...  \n",
      "178  female  47.0      1      1     11751  52.5542          D35        S  \n",
      "179    male  33.0      0      0       695   5.0000  B51 B53 B55        S  \n",
      "180  female  56.0      0      1     11767  83.1583          C50        C  \n",
      "181  female  19.0      0      0    112053  30.0000          B42        S  \n",
      "182    male  26.0      0      0    111369  30.0000         C148        C  \n",
      "\n",
      "[183 rows x 11 columns]\n",
      "\n",
      "\n",
      "y dependent variable: 0      1\n",
      "1      1\n",
      "2      0\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "178    1\n",
      "179    0\n",
      "180    1\n",
      "181    1\n",
      "182    1\n",
      "Name: Survived, Length: 183, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_independent_variables = dataset.drop(columns=[\"Survived\"])\n",
    "y_dependent_variable = dataset[\"Survived\"]\n",
    "\n",
    "print(f\"X independent variables/ Matrix of features: \\n\\n{X_independent_variables}\\n\")\n",
    "print(f\"\\ny dependent variable: {y_dependent_variable}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. One Hot Encoding - X independent variables/ Matrix of Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specifying the columns using strings is only supported for pandas DataFrames",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\__init__.py:424\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 424\u001b[0m     all_columns \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mcolumns\n\u001b[0;32m    425\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m categorical_features \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mSex\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEmbarked\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPclass\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m column_transformer \u001b[39m=\u001b[39m ColumnTransformer(transformers\u001b[39m=\u001b[39m[(\u001b[39m'\u001b[39m\u001b[39mencoder\u001b[39m\u001b[39m'\u001b[39m, OneHotEncoder(), categorical_features)], remainder\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m column_transformer\u001b[39m.\u001b[39;49mfit(X_independent_variables)\n\u001b[0;32m      4\u001b[0m X_independent_variables \u001b[39m=\u001b[39m column_transformer\u001b[39m.\u001b[39mtransform(X_independent_variables)\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mNew X independent variables: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mX_independent_variables\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:694\u001b[0m, in \u001b[0;36mColumnTransformer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit all transformers using X.\u001b[39;00m\n\u001b[0;32m    677\u001b[0m \n\u001b[0;32m    678\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39m    This estimator.\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[39m# we use fit_transform to make sure to set sparse_output_ (for which we\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[39m# need the transformed data) to have consistent output type in predict\u001b[39;00m\n\u001b[1;32m--> 694\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_transform(X, y\u001b[39m=\u001b[39;49my)\n\u001b[0;32m    695\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:724\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    723\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_transformers()\n\u001b[1;32m--> 724\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_column_callables(X)\n\u001b[0;32m    725\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m    727\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:426\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    424\u001b[0m         columns \u001b[39m=\u001b[39m columns(X)\n\u001b[0;32m    425\u001b[0m     all_columns\u001b[39m.\u001b[39mappend(columns)\n\u001b[1;32m--> 426\u001b[0m     transformer_to_input_indices[name] \u001b[39m=\u001b[39m _get_column_indices(X, columns)\n\u001b[0;32m    428\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_columns \u001b[39m=\u001b[39m all_columns\n\u001b[0;32m    429\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformer_to_input_indices \u001b[39m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\__init__.py:426\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    424\u001b[0m     all_columns \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m    425\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m--> 426\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    427\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSpecifying the columns using strings is only \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    428\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupported for pandas DataFrames\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m     )\n\u001b[0;32m    430\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    431\u001b[0m     columns \u001b[39m=\u001b[39m [key]\n",
      "\u001b[1;31mValueError\u001b[0m: Specifying the columns using strings is only supported for pandas DataFrames"
     ]
    }
   ],
   "source": [
    "categorical_features = [\"Sex\", \"Embarked\", \"Pclass\"]\n",
    "column_transformer = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), categorical_features)], remainder='passthrough')\n",
    "column_transformer.fit(X_independent_variables)\n",
    "X_independent_variables = column_transformer.transform(X_independent_variables)\n",
    "\n",
    "print(f\"\\nNew X independent variables: \\n{X_independent_variables}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Label Encoding of y dependent variable/ vector (output variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " New y dependent variable: [1 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 1\n",
      " 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1\n",
      " 0 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding - y dependent variable (output variable).\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_dependent_variable)\n",
    "y_dependent_variable = label_encoder.transform(y_dependent_variable)\n",
    "\n",
    "print(f\"\\n New y dependent variable: {y_dependent_variable}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
